import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score, roc_auc_score, average_precision_score
from sklearn.utils.class_weight import compute_class_weight
import nltk
import re
from collections import Counter
import warnings
from tqdm import tqdm
warnings.filterwarnings('ignore')

# –°–∫–∞—á–∏–≤–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

class TextPreprocessor:
    def __init__(self, language='russian'):
        self.language = language
        self.stop_words = self._get_stop_words()
        
    def _get_stop_words(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏–∑ NLTK"""
        try:
            from nltk.corpus import stopwords
            if self.language == 'russian':
                return set(stopwords.words('russian'))
            elif self.language == 'english':
                return set(stopwords.words('english'))
            else:
                return set()
        except:
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏–∑ NLTK, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –±–∞–∑–æ–≤—ã–µ")
            if self.language == 'russian':
                return {'–∏', '–≤', '–≤–æ', '–Ω–µ', '—á—Ç–æ', '–æ–Ω', '–Ω–∞', '—è', '—Å', '—Å–æ', '–∫–∞–∫', '–∞', '—Ç–æ', '–≤—Å–µ', '–æ–Ω–∞'}
            elif self.language == 'english':
                return {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
            else:
                return set()
    
    def clean_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"""
        if not isinstance(text, str) or pd.isna(text):
            return ""
        
        text = text.lower()
        text = re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9\s.,!?]', '', text)
        text = re.sub(r'\d+', '', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        words = text.split()
        words = [word for word in words if word not in self.stop_words and len(word) > 2]
        
        return ' '.join(words)
    
    def preprocess_dataframe(self, df, text_column, label_column):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞"""
        df_clean = df.copy()
        print("–ù–∞—á–∞—Ç–∞ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π...")
        
        df_clean['cleaned_text'] = df_clean[text_column].apply(self.clean_text)
        
        initial_len = len(df_clean)
        df_clean = df_clean[df_clean['cleaned_text'].str.len() > 0]
        final_len = len(df_clean)
        
        print(f"–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –£–¥–∞–ª–µ–Ω–æ {initial_len - final_len} –ø—É—Å—Ç—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        return df_clean

class TextTokenizer:
    """–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    def __init__(self, max_features=20000, max_len=200):
        self.max_features = max_features
        self.max_len = max_len
        self.word2idx = {}
        self.idx2word = {}
        self.vocab_size = 0
        
    def build_vocab(self, texts):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤"""
        print("–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è...")
        counter = Counter()
        
        for text in texts:
            words = str(text).split()
            counter.update(words)
        
        # –ë–µ—Ä–µ–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        most_common = counter.most_common(self.max_features - 2)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å
        self.word2idx = {'<PAD>': 0, '<UNK>': 1}
        for idx, (word, count) in enumerate(most_common):
            self.word2idx[word] = idx + 2
            
        self.idx2word = {idx: word for word, idx in self.word2idx.items()}
        self.vocab_size = len(self.word2idx)
        
        print(f"–°–ª–æ–≤–∞—Ä—å –ø–æ—Å—Ç—Ä–æ–µ–Ω. –†–∞–∑–º–µ—Ä: {self.vocab_size} —Å–ª–æ–≤")
        return self.word2idx, self.idx2word
    
    def texts_to_sequences(self, texts):
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–æ–≤"""
        sequences = []
        for text in texts:
            words = str(text).split()[:self.max_len]
            sequence = [self.word2idx.get(word, 1) for word in words]  # 1 = <UNK>
            
            # –ü–∞–¥–¥–∏–Ω–≥
            if len(sequence) < self.max_len:
                sequence += [0] * (self.max_len - len(sequence))  # 0 = <PAD>
            else:
                sequence = sequence[:self.max_len]
                
            sequences.append(sequence)
        
        return np.array(sequences)

class TextDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    def __init__(self, texts, labels, tokenizer):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = self.texts.iloc[idx] if hasattr(self.texts, 'iloc') else self.texts[idx]
        label = self.labels.iloc[idx] if hasattr(self.labels, 'iloc') else self.labels[idx]
        
        sequence = self.tokenizer.texts_to_sequences([text])[0]
        
        return {
            'input_ids': torch.tensor(sequence, dtype=torch.long),
            'labels': torch.tensor(label, dtype=torch.long)
        }

# =============================================================================
# –ú–û–î–ï–õ–¨ 1: HYBRID CNN + BiLSTM + ATTENTION
# =============================================================================

class HybridCNNBiLSTM(nn.Module):
    """
    –ì–∏–±—Ä–∏–¥–Ω–∞—è –º–æ–¥–µ–ª—å: CNN –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ + BiLSTM –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ + Attention –¥–ª—è –≤–∞–∂–Ω—ã—Ö —á–∞—Å—Ç–µ–π
    """
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, n_classes=3, 
                 dropout_rate=0.5, num_filters=100, kernel_sizes=[3, 4, 5]):
        super(HybridCNNBiLSTM, self).__init__()
        
        # Embedding —Å–ª–æ–π
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        
        # CNN —á–∞—Å—Ç—å –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ n-–≥—Ä–∞–º–º
        self.convs = nn.ModuleList([
            nn.Conv1d(embedding_dim, num_filters, kernel_size=k, padding=k//2)
            for k in kernel_sizes
        ])
        self.cnn_dropout = nn.Dropout(dropout_rate)
        self.cnn_pool = nn.AdaptiveMaxPool1d(1)
        
        # BiLSTM —á–∞—Å—Ç—å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, 
                           bidirectional=True, dropout=dropout_rate)
        self.lstm_dropout = nn.Dropout(dropout_rate)
        
        # Attention –º–µ—Ö–∞–Ω–∏–∑–º
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_dim * 2,  # bidirectional
            num_heads=8,
            dropout=dropout_rate,
            batch_first=True
        )
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        cnn_output_size = num_filters * len(kernel_sizes)
        lstm_output_size = hidden_dim * 2  # bidirectional
        
        self.classifier = nn.Sequential(
            nn.Linear(cnn_output_size + lstm_output_size, 512),
            nn.ReLU(),
            nn.BatchNorm1d(512),
            nn.Dropout(dropout_rate),
            
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(dropout_rate),
            
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            
            nn.Linear(128, n_classes)
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self._init_weights()
    
    def _init_weights(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
            elif isinstance(module, nn.LSTM):
                for name, param in module.named_parameters():
                    if 'weight' in name:
                        nn.init.orthogonal_(param)
                    elif 'bias' in name:
                        nn.init.zeros_(param)
    
    def forward(self, input_ids):
        # Embedding
        x_embed = self.embedding(input_ids)  # [batch_size, seq_len, embedding_dim]
        
        # CNN branch
        x_cnn = x_embed.transpose(1, 2)  # [batch_size, embedding_dim, seq_len]
        cnn_outputs = []
        for conv in self.convs:
            conv_out = torch.relu(conv(x_cnn))
            pooled = self.cnn_pool(conv_out).squeeze(-1)  # [batch_size, num_filters]
            cnn_outputs.append(pooled)
        
        x_cnn_combined = torch.cat(cnn_outputs, dim=1)  # [batch_size, num_filters * len(kernel_sizes)]
        x_cnn_combined = self.cnn_dropout(x_cnn_combined)
        
        # BiLSTM branch
        lstm_out, (hidden, cell) = self.lstm(x_embed)  # [batch_size, seq_len, hidden_dim*2]
        
        # Attention
        attn_out, attn_weights = self.attention(
            lstm_out, lstm_out, lstm_out
        )  # [batch_size, seq_len, hidden_dim*2]
        
        # –ë–µ—Ä–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É
        x_lstm = attn_out.mean(dim=1)  # [batch_size, hidden_dim*2]
        x_lstm = self.lstm_dropout(x_lstm)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º CNN –∏ LSTM –≤—ã—Ö–æ–¥—ã
        x_combined = torch.cat([x_cnn_combined, x_lstm], dim=1)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        return self.classifier(x_combined)

# =============================================================================
# –ú–û–î–ï–õ–¨ 2: DEEP BiLSTM WITH ATTENTION
# =============================================================================

class DeepBiLSTMAttention(nn.Module):
    """
    –ì–ª—É–±–æ–∫–∞—è BiLSTM —Å–µ—Ç—å —Å –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –≤–Ω–∏–º–∞–Ω–∏—è
    –ü—Ä–æ—Å—Ç–∞—è –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    """
    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256, 
                 n_layers=3, n_classes=3, dropout_rate=0.5):
        super(DeepBiLSTMAttention, self).__init__()
        
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.embedding_dropout = nn.Dropout(dropout_rate)
        
        # –ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–π BiLSTM
        self.lstm = nn.LSTM(
            embedding_dim, hidden_dim, n_layers, 
            batch_first=True, bidirectional=True, dropout=dropout_rate
        )
        
        # Attention mechanism
        self.attention = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.Tanh(),
            nn.Linear(hidden_dim, 1)
        )
        
        # Classifier
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim * 2, 256),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(128, n_classes)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        for module in self.modules():
            if isinstance(module, nn.Linear):
                nn.init.xavier_uniform_(module.weight)
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    def forward(self, input_ids):
        # Embedding
        x = self.embedding(input_ids)
        x = self.embedding_dropout(x)
        
        # LSTM
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # Attention
        attention_weights = torch.softmax(self.attention(lstm_out), dim=1)
        context_vector = torch.sum(attention_weights * lstm_out, dim=1)
        
        # Classification
        return self.classifier(context_vector)

class NeuralTextClassifier:
    def __init__(self, language='russian', device=None):
        self.language = language
        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')
        self.models = {}
        self.metrics = {}
        self.preprocessor = TextPreprocessor(language)
        self.tokenizer = None
        self.error_analysis = {}
        self.X_train = None
        self.y_train = None
        
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        if self.device == 'cuda':
            print(f"GPU: {torch.cuda.get_device_name()}")
    
    def load_and_prepare_data(self, file_path, text_column='cleaned_comment', label_column='label'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π...")
        df = pd.read_csv(file_path)
        
        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞
        df_processed = self.preprocessor.preprocess_dataframe(df, text_column, label_column)
        
        X = df_processed['cleaned_text']
        y = df_processed[label_column]
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –ø–æ–∑–∂–µ
        self.X_train_full = X
        self.y_train_full = y
        
        # –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è
        self.tokenizer = TextTokenizer(max_features=30000, max_len=200)
        self.tokenizer.build_vocab(X_train)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
        train_dataset = TextDataset(X_train, y_train, self.tokenizer)
        test_dataset = TextDataset(X_test, y_test, self.tokenizer)
        
        # DataLoader'—ã
        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)
        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)
        
        print(f"\n–î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã:")
        print(f"–¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} samples")
        print(f"–¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)} samples")
        print(f"–†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è: {self.tokenizer.vocab_size}")
        print(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: 64")
        
        return train_loader, test_loader, X_test, y_test
    
    def calculate_class_weights(self, y_train):
        """–†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å"""
        classes = np.unique(y_train)
        weights = compute_class_weight('balanced', classes=classes, y=y_train)
        class_weights = torch.tensor(weights, dtype=torch.float32).to(self.device)
        
        print(f"–í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {dict(zip(classes, weights))}")
        return class_weights
    
    def train_model(self, model, model_name, train_loader, val_loader, class_weights, epochs=10):
        """–û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–π –º–æ–¥–µ–ª–∏"""
        print(f"\nüéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è {model_name}...")
        
        criterion = nn.CrossEntropyLoss(weight=class_weights)
        optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
        
        train_losses = []
        val_accuracies = []
        best_accuracy = 0
        patience = 3
        patience_counter = 0
        
        for epoch in range(epochs):
            # Training
            model.train()
            total_loss = 0
            train_correct = 0
            train_total = 0
            
            for batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                optimizer.zero_grad()
                outputs = model(input_ids)
                loss = criterion(outputs, labels)
                loss.backward()
                
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                total_loss += loss.item()
                
                # Calculate training accuracy
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            scheduler.step()
            
            # Validation
            val_accuracy, val_predictions, val_probabilities, val_labels = self.evaluate_model(model, val_loader)
            train_accuracy = train_correct / train_total
            avg_loss = total_loss / len(train_loader)
            
            train_losses.append(avg_loss)
            val_accuracies.append(val_accuracy)
            
            print(f'Epoch {epoch+1}:')
            print(f'  Loss: {avg_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}')
            print(f'  Learning Rate: {scheduler.get_last_lr()[0]:.2e}')
            
            # Early stopping
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                patience_counter = 0
                torch.save(model.state_dict(), f'best_{model_name.replace(" ", "_").lower()}.pth')
                print(f"  üéØ –ù–æ–≤—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å.")
            else:
                patience_counter += 1
                print(f"  ‚è≥ Early stopping: {patience_counter}/{patience}")
                
            if patience_counter >= patience:
                print(f"  üõë Early stopping –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                break
        
        print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ {model_name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.4f}")
        
        # Load best model
        model.load_state_dict(torch.load(f'best_{model_name.replace(" ", "_").lower()}.pth'))
        
        return train_losses, val_accuracies
    
    def evaluate_model(self, model, data_loader):
        """–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏"""
        model.eval()
        correct = 0
        total = 0
        all_predictions = []
        all_labels = []
        all_probabilities = []
        
        with torch.no_grad():
            for batch in data_loader:
                input_ids = batch['input_ids'].to(self.device)
                labels = batch['labels'].to(self.device)
                
                outputs = model(input_ids)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs.data, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
                
                all_predictions.extend(predicted.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                all_probabilities.extend(probabilities.cpu().numpy())
        
        accuracy = correct / total
        return accuracy, all_predictions, all_probabilities, all_labels
    
    def train_all_models(self, train_loader, val_loader, y_train):
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        class_weights = self.calculate_class_weights(y_train)
        
        # –ú–æ–¥–µ–ª—å 1: Hybrid CNN + BiLSTM + Attention
        model1 = HybridCNNBiLSTM(
            vocab_size=self.tokenizer.vocab_size,
            embedding_dim=128,
            hidden_dim=256,
            n_classes=3,
            dropout_rate=0.5
        ).to(self.device)
        
        print(f"\nüîÑ –ú–û–î–ï–õ–¨ 1: Hybrid CNN-BiLSTM-Attention")
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model1.parameters()):,}")
        
        train_losses1, val_accuracies1 = self.train_model(
            model1, "Hybrid CNN-BiLSTM", train_loader, val_loader, class_weights, epochs=15
        )
        
        # –ú–æ–¥–µ–ª—å 2: Deep BiLSTM with Attention
        model2 = DeepBiLSTMAttention(
            vocab_size=self.tokenizer.vocab_size,
            embedding_dim=128,
            hidden_dim=256,
            n_layers=3,
            n_classes=3,
            dropout_rate=0.5
        ).to(self.device)
        
        print(f"\nüîÑ –ú–û–î–ï–õ–¨ 2: Deep BiLSTM with Attention")
        print(f"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model2.parameters()):,}")
        
        train_losses2, val_accuracies2 = self.train_model(
            model2, "Deep BiLSTM", train_loader, val_loader, class_weights, epochs=15
        )
        
        self.models = {
            'Hybrid CNN-BiLSTM': model1,
            'Deep BiLSTM': model2
        }
        
        return {
            'Hybrid CNN-BiLSTM': (train_losses1, val_accuracies1),
            'Deep BiLSTM': (train_losses2, val_accuracies2)
        }
    
    def comprehensive_evaluation(self, test_loader, X_test, y_test):
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        for model_name, model in self.models.items():
            print(f"\n{'='*60}")
            print(f"üìä –û–¶–ï–ù–ö–ê {model_name.upper()}")
            print(f"{'='*60}")
            
            accuracy, predictions, probabilities, true_labels = self.evaluate_model(model, test_loader)
            
            y_true = np.array(true_labels)
            y_pred = np.array(predictions)
            y_proba = np.array(probabilities)
            
            # –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
            metrics = {
                'accuracy': accuracy_score(y_true, y_pred),
                'macro_f1': f1_score(y_true, y_pred, average='macro'),
                'weighted_f1': f1_score(y_true, y_pred, average='weighted'),
                'confusion_matrix': confusion_matrix(y_true, y_pred),
                'roc_auc_ovr': roc_auc_score(y_true, y_proba, multi_class='ovr', average='macro'),
                'roc_auc_ovo': roc_auc_score(y_true, y_proba, multi_class='ovo', average='macro'),
                'pr_auc': average_precision_score(y_true, y_proba, average='macro'),
                'classification_report': classification_report(y_true, y_pred, output_dict=True)
            }
            
            self.metrics[model_name] = metrics
            
            # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            print(f"Accuracy: {metrics['accuracy']:.4f}")
            print(f"Macro F1: {metrics['macro_f1']:.4f}")
            print(f"Weighted F1: {metrics['weighted_f1']:.4f}")
            print(f"ROC-AUC (OvR): {metrics['roc_auc_ovr']:.4f}")
            print(f"PR-AUC: {metrics['pr_auc']:.4f}")
            
            print(f"\n–î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º:")
            print(classification_report(y_true, y_pred, target_names=['–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π', '–û—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–π', '–¢–æ–∫—Å–∏—á–Ω—ã–π']))
            
            # –í—ã–≤–æ–¥ confusion matrix
            self._print_confusion_matrix(model_name, metrics['confusion_matrix'])
            
            # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
            self._analyze_errors(model_name, y_true, y_pred, X_test)
    
    def _print_confusion_matrix(self, model_name, cm):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ confusion matrix"""
        print(f"\nüìã CONFUSION MATRIX - {model_name.upper()}:")
        print(" " * 15 + "Predicted ‚Üí")
        print(" " * 12 + "–ù–µ–π—Ç—Ä  –û—Å–∫–æ—Ä–±  –¢–æ–∫—Å–∏—á")
        
        class_names = ['–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π', '–û—Å–∫–æ—Ä–±–∏—Ç–µ–ª—å–Ω—ã–π', '–¢–æ–∫—Å–∏—á–Ω—ã–π']
        for i, true_class in enumerate(class_names):
            row_label = f"True {true_class[:6]}"
            print(f"{row_label:12}", end="")
            for j in range(3):
                print(f"{cm[i, j]:6}  ", end="")
            print()
        
        # –ê–Ω–∞–ª–∏–∑ –º–∞—Ç—Ä–∏—Ü—ã
        total = cm.sum()
        accuracy = np.trace(cm) / total
        print(f"\n–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {accuracy:.3f}")
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–ª–∞—Å—Å–∞–º
        for i, class_name in enumerate(class_names):
            precision = cm[i,i] / cm[:,i].sum() if cm[:,i].sum() > 0 else 0
            recall = cm[i,i] / cm[i,:].sum() if cm[i,:].sum() > 0 else 0
            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
            print(f"{class_name}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}")
    
    def _analyze_errors(self, model_name, y_true, y_pred, X_test):
        """–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        errors = {
            'false_positives': [],
            'false_negatives': [], 
            'confusions': []
        }
        
        for i, (true, pred, text) in enumerate(zip(y_true, y_pred, X_test)):
            text_length = len(str(text).split())
            
            if true == 0 and pred != 0:
                errors['false_positives'].append({
                    'text': text,
                    'true_class': true,
                    'pred_class': pred,
                    'length': text_length
                })
            elif true != 0 and pred == 0:
                errors['false_negatives'].append({
                    'text': text,
                    'true_class': true,
                    'pred_class': pred,
                    'length': text_length
                })
            elif true != pred and true != 0 and pred != 0:
                errors['confusions'].append({
                    'text': text,
                    'true_class': true,
                    'pred_class': pred,
                    'length': text_length
                })
        
        self.error_analysis[model_name] = errors
        
        print(f"\nüîç –ê–ù–ê–õ–ò–ó –û–®–ò–ë–û–ö –î–õ–Ø {model_name}:")
        print(f"False Positives (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ ‚Üí –æ–ø–∞—Å–Ω—ã–µ): {len(errors['false_positives'])}")
        print(f"False Negatives (–æ–ø–∞—Å–Ω—ã–µ ‚Üí –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ): {len(errors['false_negatives'])}")
        print(f"Confusions (–æ—à–∏–±–∫–∏ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏): {len(errors['confusions'])}")
        
        # –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫
        if errors['false_positives']:
            print(f"\nüìù –ü—Ä–∏–º–µ—Ä False Positive:")
            sample = errors['false_positives'][0]
            print(f"  –¢–µ–∫—Å—Ç: {sample['text'][:100]}...")
            print(f"  –ò—Å—Ç–∏–Ω–Ω—ã–π: {sample['true_class']}, –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π: {sample['pred_class']}")
    
    def plot_training_history(self, training_history):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        colors = ['blue', 'red', 'green']
        model_names = list(training_history.keys())
        
        for idx, model_name in enumerate(model_names):
            train_losses, val_accuracies = training_history[model_name]
            
            # Loss
            axes[0, 0].plot(train_losses, label=model_name, color=colors[idx], linewidth=2)
            axes[0, 0].set_title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ')
            axes[0, 0].set_xlabel('–≠–ø–æ—Ö–∞')
            axes[0, 0].set_ylabel('Loss')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # Accuracy
            axes[0, 1].plot(val_accuracies, label=model_name, color=colors[idx], linewidth=2)
            axes[0, 1].set_title('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏')
            axes[0, 1].set_xlabel('–≠–ø–æ—Ö–∞')
            axes[0, 1].set_ylabel('Accuracy')
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        metrics_comparison = []
        for model_name, metrics in self.metrics.items():
            metrics_comparison.append({
                'Model': model_name,
                'Accuracy': metrics['accuracy'],
                'Macro F1': metrics['macro_f1'],
                'ROC-AUC': metrics['roc_auc_ovr']
            })
        
        df_metrics = pd.DataFrame(metrics_comparison)
        
        # Bar plot –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        x = np.arange(len(df_metrics))
        width = 0.25
        
        metrics_to_plot = ['Accuracy', 'Macro F1', 'ROC-AUC']
        for i, metric in enumerate(metrics_to_plot):
            axes[1, 0].bar(x + i*width, df_metrics[metric], width, label=metric, alpha=0.8)
        
        axes[1, 0].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π')
        axes[1, 0].set_xlabel('–ú–æ–¥–µ–ª–∏')
        axes[1, 0].set_ylabel('Score')
        axes[1, 0].set_xticks(x + width)
        axes[1, 0].set_xticklabels(df_metrics['Model'], rotation=45)
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # Confusion matrices
        for idx, (model_name, metrics) in enumerate(self.metrics.items()):
            cm = metrics['confusion_matrix']
            row = 1
            col = 1
            im = axes[row, col].imshow(cm, cmap='Blues', aspect='auto')
            axes[row, col].set_title(f'Confusion Matrix - {model_name}')
            axes[row, col].set_xticks([0, 1, 2])
            axes[row, col].set_yticks([0, 1, 2])
            axes[row, col].set_xticklabels(['–ù–µ–π—Ç—Ä', '–û—Å–∫–æ—Ä–±', '–¢–æ–∫—Å–∏—á'])
            axes[row, col].set_yticklabels(['–ù–µ–π—Ç—Ä', '–û—Å–∫–æ—Ä–±', '–¢–æ–∫—Å–∏—á'])
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            for i in range(3):
                for j in range(3):
                    axes[row, col].text(j, i, f'{cm[i, j]}', 
                                      ha='center', va='center', 
                                      color='white' if cm[i, j] > cm.max()/2 else 'black')
        
        plt.tight_layout()
        plt.show()
    
    def plot_metrics_comparison(self):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        metrics_df = pd.DataFrame({
            model: {
                'Accuracy': metrics['accuracy'],
                'Macro F1': metrics['macro_f1'],
                'Weighted F1': metrics['weighted_f1'],
                'ROC-AUC': metrics['roc_auc_ovr'],
                'PR-AUC': metrics['pr_auc']
            }
            for model, metrics in self.metrics.items()
        }).T
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 10))
        axes = axes.ravel()
        
        metrics_to_plot = ['Accuracy', 'Macro F1', 'Weighted F1', 'ROC-AUC', 'PR-AUC']
        
        for idx, metric in enumerate(metrics_to_plot):
            ax = axes[idx]
            colors = ['lightblue', 'lightcoral']
            bars = ax.bar(range(len(metrics_df)), metrics_df[metric], color=colors, alpha=0.8)
            ax.set_title(f'–°—Ä–∞–≤–Ω–µ–Ω–∏–µ {metric}', fontsize=14)
            ax.set_ylabel(metric, fontsize=12)
            ax.set_xticks(range(len(metrics_df)))
            ax.set_xticklabels(metrics_df.index, rotation=45)
            
            for bar in bars:
                height = bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., height,
                       f'{height:.3f}', ha='center', va='bottom')
        
        axes[5].set_visible(False)
        plt.tight_layout()
        plt.show()
        
        return metrics_df

def run_neural_networks(file_path, text_column='cleaned_comment', label_column='label', language='russian'):
    """
    –ü–æ–ª–Ω—ã–π –∑–∞–ø—É—Å–∫ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤
    """
    print("üß† –ó–ê–ü–£–°–ö –ù–ï–ô–†–û–°–ï–¢–ï–í–´–• –ú–û–î–ï–õ–ï–ô (PyTorch)")
    print("="*70)
    print(f"–Ø–∑—ã–∫: {language}")
    print(f"–§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö: {file_path}")
    print("="*70)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
    classifier = NeuralTextClassifier(language=language)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_loader, test_loader, X_test, y_test = classifier.load_and_prepare_data(
        file_path, text_column, label_column
    )
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/validation
    dataset_size = len(train_loader.dataset)
    train_size = int(0.9 * dataset_size)
    val_size = dataset_size - train_size
    
    train_subset, val_subset = torch.utils.data.random_split(
        train_loader.dataset, [train_size, val_size]
    )
    
    train_loader_sub = DataLoader(train_subset, batch_size=64, shuffle=True)
    val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)
    
    # –ü–æ–ª—É—á–∞–µ–º y_train –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤
    y_train = [classifier.y_train_full.iloc[i] for i in train_subset.indices]
    
    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    training_history = classifier.train_all_models(train_loader_sub, val_loader, y_train)
    
    # –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
    classifier.comprehensive_evaluation(test_loader, X_test, y_test)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    classifier.plot_training_history(training_history)
    metrics_df = classifier.plot_metrics_comparison()
    
    # –í—ã–≤–æ–¥ –∏—Ç–æ–≥–æ–≤–æ–π —Ç–∞–±–ª–∏—Ü—ã
    print("\n" + "="*80)
    print("–ò–¢–û–ì–û–í–ê–Ø –¢–ê–ë–õ–ò–¶–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í - –ù–ï–ô–†–û–°–ï–¢–ò")
    print("="*80)
    print(metrics_df.round(4))
    
    # –ê–Ω–∞–ª–∏–∑ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model = metrics_df['Macro F1'].idxmax()
    best_score = metrics_df.loc[best_model, 'Macro F1']
    print(f"\nüèÜ –õ–£–ß–®–ê–Ø –ù–ï–ô–†–û–°–ï–¢–ï–í–ê–Ø –ú–û–î–ï–õ–¨: {best_model} (Macro F1: {best_score:.4f})")
    
    return classifier

if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    try:
        results = run_neural_networks(
            file_path='train_m.csv',
            text_column='comment_text', 
            label_column='label',
            language='russian'
        )
        
