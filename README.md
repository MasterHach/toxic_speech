# toxic_speech

Датасет: Jigsaw Toxic Comment Classification Challenge с переработанной разметкой для 3-х классовной классификации:

Класс 0 (Нейтральный): Комментарии без каких-либо токсичных меток

Класс 1 (Оскорбительный): Комментарии с метками toxic, obscene, insult, identity_hate

Класс 2 (Токсичный): Комментарии с метками severe_toxic, threat (наиболее опасные)

Метод классификации: Ансамбль CNN + LSTM для многоклассовой классификации.

Обоснование выбора метода:

1) CNN: Эффективно выявляет локальные паттерны и ключевые фразы, характерные для каждого класса. Например, определенные оскорбительные выражения (CNN) vs прямые угрозы (тоже CNN, но другие паттерны).

2) LSTM: Анализирует контекст и последовательности, что важно для различения:

- Прямых оскорблений vs упоминаний оскорблений

- Иронии и сарказма

- Контекстно-зависимых угроз

3) Ансамблевый подход: Объединение позволяет учитывать как локальные лексические маркеры (CNN), так и глобальный контекст (LSTM), что критически важно для различения тонких градаций между "оскорбительным" и "токсичным".

4) Работа с дисбалансом: Использование весов классов и softmax активации на выходе позволяет модели адекватно обучаться на неравномерно распределенных данных.

Основные проблемы:

- Сильный дисбаланс классов

- Субъективная граница между "оскорбительным" и "токсичным"

- Наличие завуалированных и контекстно-зависимых оскорблений
